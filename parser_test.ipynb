{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "короче это ток для хабра, достаем текст без кода и тэгов, приводим к нижнему регистру нормальной форме удаляем стоп слова пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "from bs4 import BeautifulSoup # Для обработки HTML\n",
    "import re\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"www.habrahabr.ru\") # создаем socket для подключения \n",
    "conn.request( \"GET\", \"https://habr.com/post/280238/\") # отправляем GET-запрос по указанной странице\n",
    "r = conn.getresponse() # получаем http ответ\n",
    "field = r.read() # из ответа получаем html-страницу\n",
    "conn.close() # закрываем соединение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(field, \"lxml\") # создаем объект BeautifulSoup из полученного документа\n",
    "#full_article = soup.find_all(\"div\", class_=\"post__text post__text-html js-mediator-article\")\n",
    "# ищем в документе все элементы div с атрибутом класса post__text post__text-html js-mediator-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_text = \" \"\n",
    "[s.extract() for s in soup('code')]\n",
    "for node in soup.find_all(\"div\", class_=\"post__text post__text-html js-mediator-article\"):\n",
    "    clear_text += str(node.find_all(text=True)).replace(\"\\\\n\", \"\").replace(\"\\\\r\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [\\'Введение\\', \\'Недавно заглянув на КиноПоиск, я обнаружила, что за долгие годы успела оставить более 1000 оценок и подумала, что было бы интересно поисследовать эти данные подробнее: менялись ли мои вкусы в кино с течением времени? есть ли годовая/недельная сезонность в активности? коррелируют ли мои оценки с рейтингом КиноПоиска, IMDb или кинокритиков? \\', \\'Но прежде чем анализировать и строить красивые графики, нужно получить данные. К сожалению, многие сервисы (и КиноПоиск не исключение) не имеют публичного API, так что, приходится засучить рукава и парсить html-страницы. Именно о том, как скачать и распарсить web-cайт, я и хочу рассказать в этой статье.\\', \\'В первую очередь статья предназначена для тех, кто всегда хотел разобраться с Web Scrapping, но не доходили руки или не знал с чего начать. \\', \\'\\', \\'\\', \\'Off-topic\\', \\': к слову, \\', \\'Новый Кинопоиск\\', \\' под капотом использует запросы, которые возвращают данные об оценках в виде JSON, так что, задача могла быть решена и другим путем.\\', \\'\\', \\'\\', \\'Задача\\', \\'Задача будет состоять в том, чтобы выгрузить данные о просмотренных фильмах на КиноПоиске: название фильма (русское, английское), дату и время просмотра, оценку пользователя.\\', \\'На самом деле, можно разбить работу на 2 этапа:\\', \\'\\', \\'\\', \\'Этап 1:\\', \\' выгрузить и сохранить html-страницы \\', \\'\\', \\'Этап 2:\\', \\' распарсить html в удобный для дальнейшего анализа формат (csv, json, pandas dataframe etc.)\\', \\'\\', \\'\\', \\'Инструменты\\', \\'Для отправки http-запросов есть немало python-библиотек, наиболее известные urllib/urllib2 и Requests. На мой вкус \\', \\'Requests\\', \\' удобнее и лаконичнее, так что, буду использовать ее.\\', \\'Также необходимо выбрать библиотеку для парсинга html, небольшой research дает следующие варианты:\\', \\'\\', \\'\\', \\'re\\', \\'Регулярные выражения, конечно, нам пригодятся, но использовать только их, на мой взгляд, слишком хардкорный путь, и они \\', \\'немного не для этого\\', \\'. Были придуманы более удобные инструменты для разбора html, так что перейдем к ним. \\', \\'\\', \\'BeatifulSoup\\', \\', \\', \\'lxml\\', \\'Это две наиболее популярные библиотеки для парсинга html и выбор одной из них, скорее, обусловлен личными предпочтениями. Более того, эти библиотеки тесно переплелись: BeautifulSoup стал использовать lxml в качестве внутреннего парсера для ускорения, а в lxml был добавлен модуль soupparser. Подробнее про плюсы и минусы этих библиотек можно почитать \\', \\'в обсуждении\\', \\'. Для сравнения подходов я буду парсить данные с помощью BeautifulSoup и используя \\', \\'XPath\\', \\' селекторы в модуле lxml.html.\\', \\'\\', \\'scrapy\\', \\'Это уже не просто библиотека, а целый open-source framework для получения данных с веб-страниц. В нем есть множество полезных функций: асинхронные запросы, возможность использовать XPath и CSS селекторы для обработки данных, удобная работа с кодировками и многое другое (подробнее можно почитать \\', \\'тут\\', \\'). Если бы моя задача была не разовой выгрузкой, а production процессом, то я бы выбрала его. В текущей постановке это overkill. \\', \\'\\', \\'\\', \\'Загрузка данных\\', \\'\\', \\'Первая попытка\\', \\'Приступим к выгрузке данных. Для начала, попробуем просто получить страницу по url и сохранить в локальный файл.\\', \\'\\', \\'Открываем полученный файл и видим, что все не так просто: сайт распознал в нас робота и не спешит показывать данные.\\', \\'\\', \\'\\', \\'Разберемся, как работает браузер\\', \\'Однако, у браузера отлично получается получать информацию с сайта. Посмотрим, как именно он отправляет запрос. Для этого воспользуемся панелью \"Сеть\" в \"Инструментах разработчика\" в браузере (я использую для этого Firebug), обычно нужный нам запрос — самый продолжительный.\\', \\'\\', \\'\\', \\'\\', \\'Как мы видим, браузер также передает в headers UserAgent, cookie и еще ряд параметров. Для начала попробуем просто передать в header корректный UserAgent.\\', \\'\\', \\'На этот раз все получилось, теперь нам отдаются нужные данные. Стоит отметить, что иногда сайт также проверяет корректность cookie, в таком случае помогут \\', \\'sessions\\', \\' в библиотеке Requests.\\', \\'\\', \\'\\', \\'Скачаем все оценки\\', \\'Теперь мы умеем сохранять одну страницу с оценками. Но обычно у пользователя достаточно много оценок и нужно проитерироваться по всем страницам. Интересующий нас номер страницы легко передать непосредственно в url. Остается только вопрос: \"Как понять сколько всего страниц с оценками?\" Я решила эту проблему следующим образом: если указать слишком большой номер страницы, то нам вернется вот такая страница без таблицы с фильмами. Таким образом мы можем итерироваться по страницам до тех, пор пока находится блок с оценками фильмов (\\', \\').\\', \\'\\', \\'\\', \\'\\', \\'Полный код для загрузки данных\\', \\'\\', \\'\\', \\'Парсинг\\', \\'\\', \\'Немного про XPath\\', \\'XPath — это язык запросов к xml и xhtml документов. Мы будем использовать XPath селекторы при работе с библиотекой lxml (\\', \\'документация\\', \\'). Рассмотрим небольшой пример работы с XPath\\', \\'\\', \\'Подробнее про синтаксис XPath также можно почитать на \\', \\'W3Schools\\', \\'.\\', \\'\\', \\'\\', \\'Вернемся к нашей задаче\\', \\'Теперь перейдем непосредственно к получению данных из html. Проще всего понять как устроена html-страница используя функцию \"Инспектировать элемент\" в браузере. В данном случае все довольно просто: вся таблица с оценками заключена в теге \\', \\'. Выделим эту ноду:\\', \\'\\', \\'Каждый фильм представлен как \\', \\' или \\', \\'. Рассмотрим, как вытащить русское название фильма и ссылку на страницу фильма (также узнаем, как получить текст и значение атрибута).\\', \\'\\', \\'\\', \"Еще небольшой хинт для debug\\'a: для того, чтобы посмотреть, что внутри выбранной ноды в BeautifulSoup можно просто распечатать ее, а в lxml воспользоваться функцией \", \\' модуля etree.\\', \\'\\', \\'\\', \\'Полный код для парсинга html-файлов под катом\\', \\'\\', \\'\\', \\'Резюме\\', \\'В результате, мы научились парсить web-сайты, познакомились с библиотеками Requests, BeautifulSoup и lxml, а также получили пригодные для дальнейшего анализа данные о просмотренных фильмах на КиноПоиске. \\', \\'\\', \\'Полный код проекта можно найти на \\', \"github\\'e\", \\'.\\', \\'\\', \\'\\', \\'UPD\\', \\'Как отметили в \\', \\'комментариях\\', \", в контексте Web Scrapping\\'a могут оказаться полезны следующие темы:\", \\'\\', \\'\\', \\'Аутентификация:\\', \\' зачастую для того, чтобы получить данные с сайта нужно пройти аутентификацию, в простейшем случае это просто HTTP Basic Auth: логин и пароль. Тут нам снова \\', \\'поможет\\', \\' библиотека Requests. Кроме того, широко распространена oauth2: как использовать oauth2 в python можно почитать на \\', \\'stackoverflow\\', \\'. Также в \\', \\'комментариях\\', \\' есть пример от  \\', \\'Terras\\', \\' того, как пройти аутентификацию в web-форме.\\', \\'\\', \\'Контролы:\\', \" На сайте также могут быть дополнительные web-формы (выпадающие списки, check box\\'ы итд). Алгоритм работы с ними примерно тот же: смотрим, что посылает браузер и отправляем эти же параметры как data в POST-запрос (\", \\'Requests\\', \\', \\', \\'stackoverflow\\', \\'). Также могу порекомендовать посмотреть 2й урок \\', \\'курса \"Data Wrangling\" на Udacity\\', \\', где подробно рассмотрен пример scrapping сайта \\', \\'US Department of Transportation\\', \\' и посылка данных web-форм.\\', \\'\\']'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    #tokens = text.rstrip()\n",
    "    tokens = re.sub(\"[^\\w]\", \" \", text).split()\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    tokens = [i for i in tokens if (i not in stop_words)]    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = tokenize_text(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "введение недавно заглянуть кинопоиск обнаружить долгий год успеть оставить 1000 оценка подумать интересно поисследовать дать дробный меняться вкус кино течение время годовой недельный сезонность активность коррелировать оценка рейтинг кинопоиск imdb кинокритик прежде анализировать строить красивый графика нужно получить дать сожаление многие сервис кинопоиск исключение иметь публичный api приходиться засучить рукав парсить html страница именно скачать распарсить web cайта хотеть рассказать статья очередь статья предназначить хотеть разобраться web scrapping доходить рука знать начать off topic слово новый кинопоиск капот использовать запрос который возвращать дать оценка вид json задача мочь решить путём задача задача состоять выгрузить дать просмотреть фильм кинопоиск название фильм русский английский дата время просмотр оценка пользователь самый дело разбить работа 2 этап этап 1 выгрузить сохранить html страница этап 2 распарсить html удобный дальнейший анализ формат csv json pandas dataframe etc инструмент отправка http запрос немало python библиотека наиболее известный urllib urllib2 requests вкус requests удобный лаконичный использовать также необходимый выбрать библиотека парсинга html небольшой research давать следующий вариант re регулярный выражение пригодиться использовать взгляд слишком хардкорный путь немного это придумать удобный инструмент разбор html перейти beatifulsoup lxml это наиболее популярный библиотека парсинга html выбор скорее обусловить личный предпочтение библиотека тесно переплестись beautifulsoup стать использовать lxml качество внутренний парсер ускорение lxml добавить модуль soupparser дробный плюс минус библиотека почитать обсуждение сравнение подход парсить дать помощь beautifulsoup использовать xpath селектор модула lxml html scrapy это просто библиотека целый open source framework получение дать веб страница немой множество полезный функция асинхронный запрос возможность использовать xpath css селектор обработка дать удобный работа кодировка многий дробный почитать задача разовый выгрузка production процесс выбрать текущий постановка это overkill загрузка дать попытка приступить выгрузка дать начало попробовать просто получить страница url сохранить локальный файл открывать получить файл видеть весь просто сайт распознать робот спешить показывать дать разобраться работать браузер однако браузер отлично получаться получать информация сайт посмотреть именно отправлять запрос это воспользоваться панель сеть инструмент разработчик браузер использовать это firebug обычно нужный запрос самый продолжительный видеть браузер также передавать headers useragent cookie ещё ряд параметр начало попробовать просто передать header корректный useragent весь получиться отдаваться нужный дать стоить отметить сайт также проверять корректность cookie случай помочь sessions библиотека requests скачать весь оценка уметь сохранять страница оценка обычно пользователь достаточно оценка нужно проитерироваться весь страница интересовать номер страница легко передать непосредственно url оставаться вопрос понять сколько страница оценка решить проблема следующий образ указать слишком большой номер страница вернуться страница таблица фильм образ мочь итерироваться страница пора пока находиться блок оценка фильм полный код загрузка дать парсинга немного xpath xpath это язык запрос xml xhtml документ использовать xpath селектор работа библиотека lxml документация рассмотреть небольшой пример работа xpath дробный синтаксис xpath также почитать w3schools вернуться наш задача перейти непосредственно получение дать html простой понять устроить html страница использовать функция инспектировать элемент браузер дать случай весь довольно просто весь таблица оценка заключить тег выделить нода каждый фильм представить рассмотреть вытащить русский название фильм ссылка страница фильм также узнать получить текст значение атрибут ещё небольшой хинт debug a посмотреть внутри выбрать нода beautifulsoup просто распечатать lxml воспользоваться функция модуль etree полный код парсинга html файл кат резюме результат научиться парсить web сайт познакомиться библиотека requests beautifulsoup lxml также получить пригодный дальнейший анализ дать просмотреть фильм кинопоиск полный код проект найти github e upd отметить комментарий контекст web scrapping a мочь оказаться полезный следующий тема аутентификация зачастую получить дать сайт нужно пройти аутентификация простейшее случай это просто http basic auth логин пароль снова помочь библиотека requests кроме широко распространить oauth2 использовать oauth2 python почитать stackoverflow также комментарий пример terras пройти аутентификация web форма контролы сайт также мочь дополнительный web форма выпадать список check box ы итд алгоритм работа примерно смотреть посылать браузер отправлять параметр data post запрос requests stackoverflow также мочь порекомендовать посмотреть 2й урок курс data wrangling udacity подробно рассмотреть пример scrapping сайт us department of transportation посылка дать web форма\n"
     ]
    }
   ],
   "source": [
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем\n",
    "prog = re.compile('[А-Яа-я]+')\n",
    "all_words = prog.findall(text_tokens.lower())\n",
    "all_words = [morph.parse(token)[0].normal_form for token in all_words if not token in stopwords.words('russian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['введение',\n",
       " 'недавно',\n",
       " 'заглянуть',\n",
       " 'кинопоиск',\n",
       " 'обнаружить',\n",
       " 'долгий',\n",
       " 'год',\n",
       " 'успеть',\n",
       " 'оставить',\n",
       " 'оценка',\n",
       " 'подумать',\n",
       " 'интересно',\n",
       " 'поисследовать',\n",
       " 'дать',\n",
       " 'дробный',\n",
       " 'меняться',\n",
       " 'вкус',\n",
       " 'кино',\n",
       " 'течение',\n",
       " 'время',\n",
       " 'годовой',\n",
       " 'недельный',\n",
       " 'сезонность',\n",
       " 'активность',\n",
       " 'коррелировать',\n",
       " 'оценка',\n",
       " 'рейтинг',\n",
       " 'кинопоиск',\n",
       " 'кинокритик',\n",
       " 'прежде',\n",
       " 'анализировать',\n",
       " 'строить',\n",
       " 'красивый',\n",
       " 'график',\n",
       " 'нужно',\n",
       " 'получить',\n",
       " 'дать',\n",
       " 'сожаление',\n",
       " 'многие',\n",
       " 'сервис',\n",
       " 'кинопоиск',\n",
       " 'исключение',\n",
       " 'иметь',\n",
       " 'публичный',\n",
       " 'приходиться',\n",
       " 'засучить',\n",
       " 'рукав',\n",
       " 'парсить',\n",
       " 'страница',\n",
       " 'именно',\n",
       " 'скачать',\n",
       " 'распарсить',\n",
       " 'айта',\n",
       " 'хотеть',\n",
       " 'рассказать',\n",
       " 'статья',\n",
       " 'очередь',\n",
       " 'статья',\n",
       " 'предназначить',\n",
       " 'хотеть',\n",
       " 'разобраться',\n",
       " 'доходить',\n",
       " 'рука',\n",
       " 'знать',\n",
       " 'начать',\n",
       " 'слово',\n",
       " 'новый',\n",
       " 'кинопоиск',\n",
       " 'капот',\n",
       " 'использовать',\n",
       " 'запрос',\n",
       " 'который',\n",
       " 'возвращать',\n",
       " 'дать',\n",
       " 'оценка',\n",
       " 'вид',\n",
       " 'задача',\n",
       " 'мочь',\n",
       " 'решить',\n",
       " 'путы',\n",
       " 'метр',\n",
       " 'задача',\n",
       " 'задача',\n",
       " 'состоять',\n",
       " 'выгрузить',\n",
       " 'дать',\n",
       " 'просмотреть',\n",
       " 'фильм',\n",
       " 'кинопоиск',\n",
       " 'название',\n",
       " 'фильм',\n",
       " 'русский',\n",
       " 'английский',\n",
       " 'дата',\n",
       " 'время',\n",
       " 'просмотр',\n",
       " 'оценка',\n",
       " 'пользователь',\n",
       " 'самый',\n",
       " 'дело',\n",
       " 'разбить',\n",
       " 'работа',\n",
       " 'этап',\n",
       " 'этап',\n",
       " 'выгрузить',\n",
       " 'сохранить',\n",
       " 'страница',\n",
       " 'этап',\n",
       " 'распарсить',\n",
       " 'удобный',\n",
       " 'дальнейший',\n",
       " 'анализ',\n",
       " 'формат',\n",
       " 'инструмент',\n",
       " 'отправка',\n",
       " 'запрос',\n",
       " 'немало',\n",
       " 'библиотека',\n",
       " 'наиболее',\n",
       " 'известный',\n",
       " 'вкус',\n",
       " 'удобный',\n",
       " 'лаконичный',\n",
       " 'использовать',\n",
       " 'также',\n",
       " 'необходимый',\n",
       " 'выбрать',\n",
       " 'библиотека',\n",
       " 'парсинга',\n",
       " 'небольшой',\n",
       " 'давать',\n",
       " 'следующий',\n",
       " 'вариант',\n",
       " 'регулярный',\n",
       " 'выражение',\n",
       " 'пригодиться',\n",
       " 'использовать',\n",
       " 'взгляд',\n",
       " 'слишком',\n",
       " 'хардкорный',\n",
       " 'путь',\n",
       " 'немного',\n",
       " 'это',\n",
       " 'придумать',\n",
       " 'удобный',\n",
       " 'инструмент',\n",
       " 'разбор',\n",
       " 'перейти',\n",
       " 'это',\n",
       " 'наиболее',\n",
       " 'популярный',\n",
       " 'библиотека',\n",
       " 'парсинга',\n",
       " 'выбор',\n",
       " 'скорее',\n",
       " 'обусловить',\n",
       " 'личный',\n",
       " 'предпочтение',\n",
       " 'библиотека',\n",
       " 'тесно',\n",
       " 'переплестись',\n",
       " 'стать',\n",
       " 'использовать',\n",
       " 'качество',\n",
       " 'внутренний',\n",
       " 'парсер',\n",
       " 'ускорение',\n",
       " 'добавить',\n",
       " 'модуль',\n",
       " 'дробный',\n",
       " 'плюс',\n",
       " 'минус',\n",
       " 'библиотека',\n",
       " 'почитать',\n",
       " 'обсуждение',\n",
       " 'сравнение',\n",
       " 'подход',\n",
       " 'парсить',\n",
       " 'дать',\n",
       " 'помощь',\n",
       " 'использовать',\n",
       " 'селектор',\n",
       " 'модула',\n",
       " 'это',\n",
       " 'просто',\n",
       " 'библиотека',\n",
       " 'целый',\n",
       " 'получение',\n",
       " 'дать',\n",
       " 'веб',\n",
       " 'страница',\n",
       " 'немой',\n",
       " 'множество',\n",
       " 'полезный',\n",
       " 'функция',\n",
       " 'асинхронный',\n",
       " 'запрос',\n",
       " 'возможность',\n",
       " 'использовать',\n",
       " 'селектор',\n",
       " 'обработка',\n",
       " 'дать',\n",
       " 'удобный',\n",
       " 'работа',\n",
       " 'кодировка',\n",
       " 'многий',\n",
       " 'дробный',\n",
       " 'почитать',\n",
       " 'задача',\n",
       " 'разовый',\n",
       " 'выгрузка',\n",
       " 'процесс',\n",
       " 'выбрать',\n",
       " 'текущий',\n",
       " 'постановка',\n",
       " 'это',\n",
       " 'загрузка',\n",
       " 'дать',\n",
       " 'попытка',\n",
       " 'приступить',\n",
       " 'выгрузка',\n",
       " 'дать',\n",
       " 'начать',\n",
       " 'попробовать',\n",
       " 'просто',\n",
       " 'получить',\n",
       " 'страница',\n",
       " 'сохранить',\n",
       " 'локальный',\n",
       " 'файл',\n",
       " 'открывать',\n",
       " 'получить',\n",
       " 'файл',\n",
       " 'видеть',\n",
       " 'весь',\n",
       " 'просто',\n",
       " 'сайт',\n",
       " 'распознать',\n",
       " 'робот',\n",
       " 'спешить',\n",
       " 'показывать',\n",
       " 'дать',\n",
       " 'разобраться',\n",
       " 'работать',\n",
       " 'браузер',\n",
       " 'однако',\n",
       " 'браузер',\n",
       " 'отлично',\n",
       " 'получаться',\n",
       " 'получать',\n",
       " 'информация',\n",
       " 'сайт',\n",
       " 'посмотреть',\n",
       " 'именно',\n",
       " 'отправлять',\n",
       " 'запрос',\n",
       " 'это',\n",
       " 'воспользоваться',\n",
       " 'панель',\n",
       " 'сеть',\n",
       " 'инструмент',\n",
       " 'разработчик',\n",
       " 'браузер',\n",
       " 'использовать',\n",
       " 'это',\n",
       " 'обычно',\n",
       " 'нужный',\n",
       " 'запрос',\n",
       " 'самый',\n",
       " 'продолжительный',\n",
       " 'видеть',\n",
       " 'браузер',\n",
       " 'также',\n",
       " 'передавать',\n",
       " 'ещ',\n",
       " 'ряд',\n",
       " 'параметр',\n",
       " 'начать',\n",
       " 'попробовать',\n",
       " 'просто',\n",
       " 'передать',\n",
       " 'корректный',\n",
       " 'весь',\n",
       " 'получиться',\n",
       " 'отдаваться',\n",
       " 'нужный',\n",
       " 'дать',\n",
       " 'стоить',\n",
       " 'отметить',\n",
       " 'сайт',\n",
       " 'также',\n",
       " 'проверять',\n",
       " 'корректность',\n",
       " 'случай',\n",
       " 'помочь',\n",
       " 'библиотека',\n",
       " 'скачать',\n",
       " 'весь',\n",
       " 'оценка',\n",
       " 'уметь',\n",
       " 'сохранять',\n",
       " 'страница',\n",
       " 'оценка',\n",
       " 'обычно',\n",
       " 'пользователь',\n",
       " 'достаточно',\n",
       " 'оценка',\n",
       " 'нужно',\n",
       " 'проитерироваться',\n",
       " 'весь',\n",
       " 'страница',\n",
       " 'интересовать',\n",
       " 'номер',\n",
       " 'страница',\n",
       " 'легко',\n",
       " 'передать',\n",
       " 'непосредственно',\n",
       " 'оставаться',\n",
       " 'вопрос',\n",
       " 'понять',\n",
       " 'сколько',\n",
       " 'страница',\n",
       " 'оценка',\n",
       " 'решить',\n",
       " 'проблема',\n",
       " 'следующий',\n",
       " 'образ',\n",
       " 'указать',\n",
       " 'слишком',\n",
       " 'большой',\n",
       " 'номер',\n",
       " 'страница',\n",
       " 'вернуться',\n",
       " 'страница',\n",
       " 'таблица',\n",
       " 'фильм',\n",
       " 'образ',\n",
       " 'мочь',\n",
       " 'итерироваться',\n",
       " 'страница',\n",
       " 'пора',\n",
       " 'пока',\n",
       " 'находиться',\n",
       " 'блок',\n",
       " 'оценка',\n",
       " 'фильм',\n",
       " 'полный',\n",
       " 'код',\n",
       " 'загрузка',\n",
       " 'дать',\n",
       " 'парсинга',\n",
       " 'немного',\n",
       " 'это',\n",
       " 'язык',\n",
       " 'запрос',\n",
       " 'документ',\n",
       " 'использовать',\n",
       " 'селектор',\n",
       " 'работа',\n",
       " 'библиотека',\n",
       " 'документация',\n",
       " 'рассмотреть',\n",
       " 'небольшой',\n",
       " 'пример',\n",
       " 'работа',\n",
       " 'дробный',\n",
       " 'синтаксис',\n",
       " 'также',\n",
       " 'почитать',\n",
       " 'вернуться',\n",
       " 'наш',\n",
       " 'задача',\n",
       " 'перейти',\n",
       " 'непосредственно',\n",
       " 'получение',\n",
       " 'дать',\n",
       " 'простой',\n",
       " 'понять',\n",
       " 'устроить',\n",
       " 'страница',\n",
       " 'использовать',\n",
       " 'функция',\n",
       " 'инспектировать',\n",
       " 'элемент',\n",
       " 'браузер',\n",
       " 'дать',\n",
       " 'случай',\n",
       " 'весь',\n",
       " 'довольно',\n",
       " 'просто',\n",
       " 'весь',\n",
       " 'таблица',\n",
       " 'оценка',\n",
       " 'заключить',\n",
       " 'тег',\n",
       " 'выделить',\n",
       " 'нода',\n",
       " 'каждый',\n",
       " 'фильм',\n",
       " 'представить',\n",
       " 'рассмотреть',\n",
       " 'вытащить',\n",
       " 'русский',\n",
       " 'название',\n",
       " 'фильм',\n",
       " 'ссылка',\n",
       " 'страница',\n",
       " 'фильм',\n",
       " 'также',\n",
       " 'узнать',\n",
       " 'получить',\n",
       " 'текст',\n",
       " 'значение',\n",
       " 'атрибут',\n",
       " 'ещ',\n",
       " 'небольшой',\n",
       " 'хинт',\n",
       " 'посмотреть',\n",
       " 'внутри',\n",
       " 'выбрать',\n",
       " 'нода',\n",
       " 'просто',\n",
       " 'распечатать',\n",
       " 'воспользоваться',\n",
       " 'функция',\n",
       " 'модуль',\n",
       " 'полный',\n",
       " 'код',\n",
       " 'парсинга',\n",
       " 'файл',\n",
       " 'кат',\n",
       " 'резюме',\n",
       " 'результат',\n",
       " 'научиться',\n",
       " 'парсить',\n",
       " 'сайт',\n",
       " 'познакомиться',\n",
       " 'библиотека',\n",
       " 'также',\n",
       " 'получить',\n",
       " 'пригодный',\n",
       " 'дальнейший',\n",
       " 'анализ',\n",
       " 'дать',\n",
       " 'просмотреть',\n",
       " 'фильм',\n",
       " 'кинопоиск',\n",
       " 'полный',\n",
       " 'код',\n",
       " 'проект',\n",
       " 'найти',\n",
       " 'отметить',\n",
       " 'комментарий',\n",
       " 'контекст',\n",
       " 'мочь',\n",
       " 'оказаться',\n",
       " 'полезный',\n",
       " 'следующий',\n",
       " 'тема',\n",
       " 'аутентификация',\n",
       " 'зачастую',\n",
       " 'получить',\n",
       " 'дать',\n",
       " 'сайт',\n",
       " 'нужно',\n",
       " 'пройти',\n",
       " 'аутентификация',\n",
       " 'простейшее',\n",
       " 'случай',\n",
       " 'это',\n",
       " 'просто',\n",
       " 'логин',\n",
       " 'пароль',\n",
       " 'снова',\n",
       " 'помочь',\n",
       " 'библиотека',\n",
       " 'кроме',\n",
       " 'широко',\n",
       " 'распространить',\n",
       " 'использовать',\n",
       " 'почитать',\n",
       " 'также',\n",
       " 'комментарий',\n",
       " 'пример',\n",
       " 'пройти',\n",
       " 'аутентификация',\n",
       " 'форма',\n",
       " 'контролы',\n",
       " 'сайт',\n",
       " 'также',\n",
       " 'мочь',\n",
       " 'дополнительный',\n",
       " 'форма',\n",
       " 'выпадать',\n",
       " 'список',\n",
       " 'ы',\n",
       " 'итд',\n",
       " 'алгоритм',\n",
       " 'работа',\n",
       " 'примерно',\n",
       " 'смотреть',\n",
       " 'посылать',\n",
       " 'браузер',\n",
       " 'отправлять',\n",
       " 'параметр',\n",
       " 'запрос',\n",
       " 'также',\n",
       " 'мочь',\n",
       " 'порекомендовать',\n",
       " 'посмотреть',\n",
       " 'й',\n",
       " 'урок',\n",
       " 'курс',\n",
       " 'подробно',\n",
       " 'рассмотреть',\n",
       " 'пример',\n",
       " 'сайт',\n",
       " 'посылка',\n",
       " 'дать',\n",
       " 'форма']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('использовать', 'селектор'), 3),\n",
       " (('полный', 'код'), 3),\n",
       " (('получить', 'дать'), 2),\n",
       " (('дать', 'просмотреть'), 2),\n",
       " (('просмотреть', 'фильм'), 2),\n",
       " (('фильм', 'кинопоиск'), 2),\n",
       " (('название', 'фильм'), 2),\n",
       " (('дальнейший', 'анализ'), 2),\n",
       " (('библиотека', 'парсинга'), 2),\n",
       " (('немного', 'это'), 2),\n",
       " (('это', 'просто'), 2),\n",
       " (('получение', 'дать'), 2),\n",
       " (('загрузка', 'дать'), 2),\n",
       " (('начать', 'попробовать'), 2),\n",
       " (('попробовать', 'просто'), 2),\n",
       " (('сайт', 'также'), 2),\n",
       " (('помочь', 'библиотека'), 2),\n",
       " (('страница', 'оценка'), 2),\n",
       " (('номер', 'страница'), 2),\n",
       " (('пройти', 'аутентификация'), 2)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = list(nltk.bigrams(all_words))\n",
    "bgfd = nltk.FreqDist(bg)\n",
    "bgfd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('дать', 17),\n",
       " ('страница', 13),\n",
       " ('оценка', 10),\n",
       " ('использовать', 10),\n",
       " ('библиотека', 10),\n",
       " ('также', 9),\n",
       " ('фильм', 8),\n",
       " ('это', 8),\n",
       " ('запрос', 7),\n",
       " ('просто', 7),\n",
       " ('сайт', 7),\n",
       " ('кинопоиск', 6),\n",
       " ('получить', 6),\n",
       " ('весь', 6),\n",
       " ('браузер', 6),\n",
       " ('задача', 5),\n",
       " ('мочь', 5),\n",
       " ('работа', 5),\n",
       " ('дробный', 4),\n",
       " ('удобный', 4)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq1 = nltk.FreqDist(all_words)\n",
    "freq1.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-30dc004fd2ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkeyword_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Big Apple'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'New York'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkeyword_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bay Area'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mkeywords_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeyword_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mkeywords_found\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\flashtext\\keyword.py\u001b[0m in \u001b[0;36mextract_keywords\u001b[1;34m(self, sentence, span_info)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mkeywords_extracted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcase_sensitive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[0mcurrent_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeyword_trie_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[0msequence_start_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from flashtext.keyword import KeywordProcessor\n",
    "keyword_processor = KeywordProcessor()\n",
    "keyword_processor.add_keyword('Big Apple', 'New York')\n",
    "keyword_processor.add_keyword('Bay Area')\n",
    "keywords_found = keyword_processor.extract_keywords(f)\n",
    "keywords_found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
